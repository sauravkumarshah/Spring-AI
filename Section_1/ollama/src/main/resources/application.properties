spring.application.name=openai
logging.pattern.console=%green(%d{HH:mm:ss.SSS}) %blue(%-5level) %red([%thread]) %yellow(%logger{15}) - %msg%n
spring.ai.model.chat=ollama
spring.ai.ollama.chat.options.model=llama3.2:1b

#To test this project run the following command after starting docker desktop
# 1. docker run -d -v ollama:/root/.ollama -p 11434:11434 --name ollama ollama/ollama
# 2. docker exec -it ollama ollama run llama3.2:1b
# 3. Start the application and check from the api from postman